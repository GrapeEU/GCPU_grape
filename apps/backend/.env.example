# ========================================
# Grape Backend - Environment Variables
# ========================================
# Copy this file to .env and fill in your actual values
# NEVER commit .env to version control!

# ========================================
# Google Cloud Platform
# ========================================
GCP_PROJECT_ID=your-gcp-project-id
GCP_REGION=us-central1

# Google Cloud Storage
GCS_BUCKET_NAME=your-bucket-name

# Vertex AI (Gemini)
VERTEX_AI_LOCATION=us-central1

# Secret Manager (optional - if using GCP Secret Manager)
USE_SECRET_MANAGER=false

# ========================================
# GraphDB / SPARQL Endpoints
# ========================================
# Main Knowledge Graph endpoint
# Options: demo, hearing, psychiatry, unified
KG_SPARQL_ENDPOINT_URL=http://localhost:7200/repositories/unified

# Ontologies endpoint (can be same as KG)
ONTOLOGIES_SPARQL_ENDPOINT_URL=http://localhost:7200/repositories/unified

# GraphDB credentials (if required - Free edition doesn't need auth)
GRAPHDB_USERNAME=
GRAPHDB_PASSWORD=

# Repository mappings for multi-KG scenarios
GRAPHDB_REPO_DEMO=http://localhost:7200/repositories/demo
GRAPHDB_REPO_HEARING=http://localhost:7200/repositories/hearing
GRAPHDB_REPO_PSYCHIATRY=http://localhost:7200/repositories/psychiatry
GRAPHDB_REPO_UNIFIED=http://localhost:7200/repositories/unified

# ========================================
# LLM Providers (for gen2kgbot compatibility)
# ========================================
# OpenAI
OPENAI_API_KEY=your-openai-key

# Anthropic Claude
ANTHROPIC_API_KEY=your-anthropic-key

# DeepSeek
DEEPSEEK_API_KEY=your-deepseek-key

# OVHCloud
OVHCLOUD_API_KEY=your-ovhcloud-key

# HuggingFace
HF_TOKEN=your-huggingface-token

# Ollama (local)
OLLAMA_BASE_URL=http://localhost:11434

# ========================================
# LangChain / LangSmith
# ========================================
LANGCHAIN_API_KEY=your-langchain-api-key
LANGCHAIN_TRACING_V2=true
LANGCHAIN_PROJECT=grape-backend
LANGCHAIN_ENDPOINT=https://api.smith.langchain.com

# ========================================
# Application Settings
# ========================================
# Environment (development, staging, production)
ENVIRONMENT=development

# API settings
API_HOST=0.0.0.0
API_PORT=8000
API_RELOAD=true

# CORS origins (comma-separated)
CORS_ORIGINS=http://localhost:3000,http://localhost:8000

# Logging
LOG_LEVEL=INFO

# ========================================
# gen2kgbot Configuration
# ========================================
# Data directory for gen2kgbot preprocessing
GEN2KGBOT_DATA_DIR=./data

# Default KG configuration
KG_SHORT_NAME=default_kg
KG_FULL_NAME=Default Knowledge Graph

# Embedding model
EMBEDDING_MODEL=nomic-embed-text
EMBEDDING_PROVIDER=local

# ========================================
# MCP Tools Configuration
# ========================================
# Enable/disable specific pipelines
ENABLE_SEMANTIC_FINDER=true
ENABLE_NEIGHBOURHOOD_RETRIEVER=true
ENABLE_MULTI_HOP_EXPLORER=true
ENABLE_ONTOLOGY_BUILDER=true
ENABLE_EXAMPLE_RETRIEVER=true
ENABLE_FEDERATED_CONNECTOR=true
ENABLE_SPARQL_EXECUTOR=true
ENABLE_PROOF_ENGINE=true
ENABLE_REASONING_NARRATOR=true

# Pipeline cache settings
PIPELINE_CACHE_ENABLED=true
PIPELINE_CACHE_TTL=3600

# ========================================
# Optional: Database (if using PostgreSQL for metadata)
# ========================================
# DATABASE_URL=postgresql://user:password@localhost:5432/grape

# ========================================
# Optional: Redis (for caching)
# ========================================
# REDIS_URL=redis://localhost:6379/0
